{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8d6e476-7433-4c42-a04c-b89759144d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import magic\n",
    "import openpyxl\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluates a math expression like '2 + 2 * 3'.\"\"\"\n",
    "    try:\n",
    "        return str(eval(expression, {\"__builtins__\": {}}))\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def wiki_search(query: str) -> str:\n",
    "    \"\"\"Search Wikipedia for a query and return maximum 2 results.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query.\"\"\"\n",
    "    search_docs = WikipediaLoader(query=query, load_max_docs=2).load()\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ])\n",
    "    return {\"wiki_results\": formatted_search_docs}\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> dict:\n",
    "    \"\"\"Search Tavily and return up to 3 results formatted for the agent.\"\"\"\n",
    "    tavily = TavilySearchResults(max_results=3)\n",
    "    search_docs = tavily.invoke(query)           # list[dict]\n",
    "\n",
    "    formatted = \"\\n\\n---\\n\\n\".join(\n",
    "        f'<Document source=\"{doc.get(\"url\", \"\")}\"/>\\n{doc.get(\"content\", \"\")}\\n</Document>'\n",
    "        for doc in search_docs\n",
    "    )\n",
    "\n",
    "    return {\"web_results\": formatted}\n",
    "\n",
    "@tool\n",
    "def arvix_search(query: str) -> str:\n",
    "    \"\"\"Search Arxiv for a query and return maximum 3 result.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query.\"\"\"\n",
    "    search_docs = ArxivLoader(query=query, load_max_docs=3).load()\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content[:1000]}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ])\n",
    "    return {\"arvix_results\": formatted_search_docs}\n",
    "\n",
    "@tool\n",
    "def execute_python(code: str) -> str:\n",
    "    \"\"\"Compiles and executes a Python snippet (sandboxed).\"\"\"\n",
    "    try:\n",
    "        local_vars = {}\n",
    "        exec(code, {}, local_vars)\n",
    "        return str(local_vars.get(\"result\", \"[Executed]\"))\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def read_pdf(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts and returns text from the first few pages of a PDF file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        return f\"Error: File '{filename}' not found.\"\n",
    "        \n",
    "    doc = None\n",
    "    try:\n",
    "        doc = fitz.open(filename)\n",
    "        text = \"\"\n",
    "        for page in doc[:3]:  # Limit to first 3 pages for speed\n",
    "            text += page.get_text()\n",
    "        return text[:1000]  # Limit output to 1000 characters\n",
    "    except Exception as e:\n",
    "        return f\"Error reading PDF: {str(e)}\"\n",
    "    finally:\n",
    "        if doc:\n",
    "            doc.close()\n",
    "    \n",
    "\n",
    "@tool\n",
    "def read_spreadsheet(file_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads spreadsheet data (CSV, XLSX, XLS, TSV) and returns the first few rows as a formatted string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ext = os.path.splitext(file_name)[-1].lower()\n",
    "        \n",
    "        if ext == \".csv\":\n",
    "            df = pd.read_csv(file_name)\n",
    "        elif ext == \".tsv\":\n",
    "            df = pd.read_csv(file_name, sep=\"\\t\")\n",
    "        elif ext in [\".xlsx\", \".xls\"]:\n",
    "            df = pd.read_excel(file_name, engine=\"openpyxl\" if ext == \".xlsx\" else \"xlrd\")\n",
    "        else:\n",
    "            return f\"Unsupported file extension: {ext}\"\n",
    "\n",
    "        return df.head().to_string(index=False)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error reading spreadsheet: {str(e)}\"\n",
    "    \n",
    "@tool\n",
    "def recognize_image(image_description: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses a ChatGPT model to recognize objects in an image based on a textual description.\n",
    "    Returns the model's response.\n",
    "    \"\"\"\n",
    "    # Initialize ChatGPT model\n",
    "    chat_model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "    try:\n",
    "        prompt = f\"Describe the objects or scene in the image based on the following description: '{image_description}'.\"\n",
    "        response = chat_model.invoke(prompt)\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"Error processing image description: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7b5c4e0-fdf1-400c-bf0f-4ba78cabbe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 20:06:05,205 - __main__ - INFO - Environment variables loaded\n",
      "2025-06-14 20:06:06,092 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 20:06:14,090 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 20:06:17,090 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 20:06:19,886 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 20:06:22,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 20:06:27,047 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The only Malko Competition recipient from the 20th Century (after 1977) whose nationality on record is a country that no longer exists is **Claus Peter Flor**. He won the competition in **1980** and his nationality is recorded as **Czechoslovakia**, which dissolved in 1993.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wikipedia\n",
    "import logging\n",
    "\n",
    "from typing import TypedDict, Annotated, List\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AnyMessage\n",
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langgraph.graph import START, StateGraph, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from supabase.client import Client, create_client\n",
    "from langsmith import Client as LangSmithClient\n",
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.tracers.run_collector import RunCollectorCallbackHandler\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "logger.info(\"Environment variables loaded\")\n",
    "\n",
    "# Initialize LangSmith\n",
    "langsmith_client = LangSmithClient()\n",
    "run_collector = RunCollectorCallbackHandler()\n",
    "tracer = LangChainTracer(\n",
    "    project_name=\"gaia-agent\",\n",
    "    client=langsmith_client\n",
    ")\n",
    "callback_manager = CallbackManager([tracer, run_collector])\n",
    "\n",
    "# System prompt guiding tool use and step-by-step reasoning\n",
    "system_prompt = SystemMessage(content=\"\"\"\n",
    "You are a helpful assistant tasked with answering questions using a set of tools. \n",
    "Now, I will ask you a question. Report your thoughts, and finish your answer with the following template: \n",
    "FINAL ANSWER: [YOUR FINAL ANSWER]. \n",
    "YOUR FINAL ANSWER should be a number OR as few words as possible OR a comma separated list of numbers and/or strings. If you are asked for a number, don't use comma to write your number neither use units such as $ or percent sign unless specified otherwise. If you are asked for a string, don't use articles, neither abbreviations (e.g. for cities), and write the digits in plain text unless specified otherwise. If you are asked for a comma separated list, apply the above rules depending of whether the element to be put in the list is a number or a string.\n",
    "Your answer should only start with \"FINAL ANSWER: \", then follows with the answer. \n",
    "\"\"\")\n",
    "\n",
    "tools = [calculator, \n",
    "        read_pdf, \n",
    "        read_spreadsheet, \n",
    "        recognize_image, \n",
    "        execute_python, \n",
    "        web_search,\n",
    "        wiki_search,\n",
    "        arvix_search]\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    temperature=0,\n",
    "    callbacks=[tracer]\n",
    ")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "def assistant(state: AgentState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# 6. Build graph\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# Compile the graph agent\n",
    "agent = builder.compile()\n",
    "\n",
    "question = \"\"\"What is the first name of the only Malko Competition recipient \n",
    "from the 20th Century (after 1977) whose nationality on record is a country that \n",
    "no longer exists?\"\"\"\n",
    "    \n",
    "response = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"type\": \"user\", \"content\": question}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f8845e-e140-42f6-b93f-5c92b6a59b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
